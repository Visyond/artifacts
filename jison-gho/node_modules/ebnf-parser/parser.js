/* parser generated by jison 0.4.18-184 */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `quoteName()` to reference this function
 *               at the end of the `parse()`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack, ...),
 *               where `...` denotes the (optional) additional arguments the user passed to
 *               `parser.parse(str, ...)` and specified by way of `%parse-param ...` in the grammar file
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `yyval` internal object, which has members (`$` and `_$`)
 *                             to store/reference the rule value `$$` and location info `@$`.
 *
 *                 One important thing to note about `this` a.k.a. `yyval`: every *reduce* action gets
 *                 to see the same object via the `this` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use `yyval` a.k.a. `this` for storing you own semi-permanent data.
 *
 *               - `yytext`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, `yytext` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - `yyleng`  : ditto as `yytext`, only now for the lexer.yyleng value.
 *
 *               - `yylineno`: ditto as `yytext`, only now for the lexer.yylineno value.
 *
 *               - `yyloc`   : ditto as `yytext`, only now for the lexer.yylloc lexer token location info.
 *
 *               - `yystate` : the current parser state number, used internally for dispatching and
 *                             executing the action code chunk matching the rule currently being reduced.
 *
 *               - `yysp`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. `##$ === ##0 === yysp`, while `##1` is the stack index for all things
 *                 related to the first rule term, just like you have `$1`, `@1` and `#1`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - `yyvstack`: reference to the parser value stack. Also accessed via the `$1` etc.
 *                             constructs.
 *
 *               - `yylstack`: reference to the parser token location stack. Also accessed via
 *                             the `@1` etc. constructs.
 *
 *               - `yystack` : reference to the parser token id stack. Also accessed via the
 *                             `#1` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any `#n` reference to
 *                 its numeric token id value, hence that code wouldn't need the `yystack` but *you* might
 *                 want access for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - `yysstack`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in `yystate`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - `...`     : the extra arguments you specified in the `%parse-param` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - `state`  --> hash table
 *               - `symbol` --> action (number or array)
 *
 *                 If the `action` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO `state`
 *
 *                 If the `action` is a number, it is the GOTO `state`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   var infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   var retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic `parseError` handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `parseError()` to reference this function
 *               at the end of the `parse()`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given `input` and return the parsed value (or `true` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of this grammar:
 *               these extra `args...` are passed verbatim to the grammar rules' action code.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API is invoked at the end of the `parse()` call, unless an exception was thrown
 *               and `%options no-try-catch` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the `post_parse` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" `yy` once
 *                             received via a call to the `.setInput(input, yy)` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the `collect_expected_token_set()`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal `$$` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while `this` will reference the current parser instance.
 *
 * When `parseError` is invoked by the lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When `parseError` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the `expected` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the `.yy` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy [, optional parse() args])
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`.
 *  Parser.post_parse: function(yy, retval [, optional parse() args]) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`. When it does not return any value,
 *                 the parser will return the original `retval`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy [, optional parse() args])
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of `lex()`) but immediately after the invocation of
 *                 `parser.pre_parse()`).
 *      post_parse: function(yy, retval [, optional parse() args]) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 `retval` contains the return value to be produced by `Parser.parse()`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 `retval`.
 *                 This function is invoked immediately before `Parser.post_parse()`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *      quoteName: function(name),
 *                 optional: overrides the default `quoteName` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */
var bnf = (function () {

// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) { // V8
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError.prototype, Error.prototype);
} else {
    JisonParserError.prototype = Object.create(Error.prototype);
}
JisonParserError.prototype.constructor = JisonParserError;
JisonParserError.prototype.name = 'JisonParserError';




// helper: reconstruct the productions[] table
function bp(s) {
    var rv = [];
    var p = s.pop;
    var r = s.rule;
    for (var i = 0, l = p.length; i < l; i++) {
        rv.push([
            p[i],
            r[i]
        ]);
    }
    return rv;
}



// helper: reconstruct the defaultActions[] table
function bda(s) {
    var rv = {};
    var d = s.idx;
    var g = s.goto;
    for (var i = 0, l = d.length; i < l; i++) {
        var j = d[i];
        rv[j] = g[i];
    }
    return rv;
}



// helper: reconstruct the 'goto' table
function bt(s) {
    var rv = [];
    var d = s.len;
    var y = s.symbol;
    var t = s.type;
    var a = s.state;
    var m = s.mode;
    var g = s.goto;
    for (var i = 0, l = d.length; i < l; i++) {
        var n = d[i];
        var q = {};
        for (var j = 0; j < n; j++) {
            var z = y.shift();
            switch (t.shift()) {
            case 2:
                q[z] = [
                    m.shift(),
                    g.shift()
                ];
                break;

            case 0:
                q[z] = a.shift();
                break;

            default:
                // type === 1: accept
                q[z] = [
                    3
                ];
            }
        }
        rv.push(q);
    }
    return rv;
}



// helper: runlength encoding with increment step: code, length: step (default step = 0)
// `this` references an array
function s(c, l, a) {
    a = a || 0;
    for (var i = 0; i < l; i++) {
        this.push(c);
        c += a;
    }
}

// helper: duplicate sequence from *relative* offset and length.
// `this` references an array
function c(i, l) {
    i = this.length - i;
    for (l += i; i < l; i++) {
        this.push(this[i]);
    }
}

// helper: unpack an array using helpers and data, all passed in an array argument 'a'.
function u(a) {
    var rv = [];
    for (var i = 0, l = a.length; i < l; i++) {
        var e = a[i];
        // Is this entry a helper function?
        if (typeof e === 'function') {
            i++;
            e.apply(rv, a[i]);
        } else {
            rv.push(e);
        }
    }
    return rv;
}


var parser = {
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   no default action: ............... false
    //   no try..catch: ................... false
    //   no default resolve on conflict:    false
    //   on-demand look-ahead: ............ false
    //   error recovery token skip maximum: 3
    //   yyerror in parse actions is: ..... NOT recoverable,
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. NOT recoverable,
    //   debug grammar/output: ............ false
    //   has partial LR conflict upgrade:   true
    //   rudimentary token-stack support:   false
    //   parser table compression mode: ... 2
    //   export debug tables: ............. false
    //   export *all* tables: ............. false
    //   module type: ..................... commonjs
    //   parser engine type: .............. lalr
    //   output main() in the module: ..... true
    //   number of expected conflicts: .... 0
    //
    //
    // Parser Analysis flags:
    //
    //   all actions are default: ......... false
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses ParseError API: ............. false
    //   uses YYERROR: .................... true
    //   uses YYRECOVERING: ............... false
    //   uses YYERROK: .................... false
    //   uses YYCLEARIN: .................. false
    //   tracks rule values: .............. true
    //   assigns rule values: ............. true
    //   uses location tracking: .......... true
    //   assigns location: ................ false
    //   uses yystack: .................... false
    //   uses yysstack: ................... false
    //   uses yysp: ....................... true
    //   has error recovery: .............. true
    //
    // --------- END OF REPORT -----------

trace: function no_op_trace() { },
JisonParserError: JisonParserError,
yy: {},
options: {
  type: "lalr",
  hasPartialLrUpgradeOnConflict: true,
  errorRecoveryTokenDiscardCount: 3
},
symbols_: {
  "$accept": 0,
  "$end": 1,
  "%%": 14,
  "(": 7,
  ")": 8,
  "*": 9,
  "+": 11,
  ":": 4,
  ";": 5,
  "=": 3,
  "?": 10,
  "ACTION": 15,
  "ACTION_BODY": 41,
  "ALIAS": 38,
  "ARROW_ACTION": 40,
  "CODE": 44,
  "DEBUG": 19,
  "EOF": 1,
  "EPSILON": 37,
  "ID": 23,
  "IMPORT": 21,
  "INCLUDE": 42,
  "INIT_CODE": 22,
  "INTEGER": 36,
  "LEFT": 32,
  "LEX_BLOCK": 17,
  "NAME": 27,
  "NONASSOC": 34,
  "OPTIONS": 25,
  "OPTIONS_END": 26,
  "OPTION_STRING_VALUE": 28,
  "OPTION_VALUE": 29,
  "PARSER_TYPE": 31,
  "PARSE_PARAM": 30,
  "PATH": 43,
  "PREC": 39,
  "RIGHT": 33,
  "START": 16,
  "STRING": 24,
  "TOKEN": 18,
  "TOKEN_TYPE": 35,
  "UNKNOWN_DECL": 20,
  "action": 80,
  "action_body": 81,
  "action_comments_body": 82,
  "action_ne": 79,
  "associativity": 58,
  "declaration": 49,
  "declaration_list": 48,
  "error": 2,
  "expression": 74,
  "extra_parser_module_code": 83,
  "full_token_definitions": 60,
  "grammar": 66,
  "handle": 71,
  "handle_action": 70,
  "handle_list": 69,
  "handle_sublist": 72,
  "id": 78,
  "id_list": 65,
  "import_name": 50,
  "import_path": 51,
  "include_macro_code": 84,
  "module_code_chunk": 85,
  "one_full_token": 61,
  "operator": 57,
  "option": 54,
  "option_list": 53,
  "optional_action_header_block": 47,
  "optional_end_block": 46,
  "optional_module_code_chunk": 86,
  "optional_token_type": 62,
  "options": 52,
  "parse_params": 55,
  "parser_type": 56,
  "prec": 76,
  "production": 68,
  "production_list": 67,
  "spec": 45,
  "suffix": 75,
  "suffixed_expression": 73,
  "symbol": 77,
  "token_description": 64,
  "token_list": 59,
  "token_value": 63,
  "{": 12,
  "|": 6,
  "}": 13
},
terminals_: {
  1: "EOF",
  2: "error",
  3: "=",
  4: ":",
  5: ";",
  6: "|",
  7: "(",
  8: ")",
  9: "*",
  10: "?",
  11: "+",
  12: "{",
  13: "}",
  14: "%%",
  15: "ACTION",
  16: "START",
  17: "LEX_BLOCK",
  18: "TOKEN",
  19: "DEBUG",
  20: "UNKNOWN_DECL",
  21: "IMPORT",
  22: "INIT_CODE",
  23: "ID",
  24: "STRING",
  25: "OPTIONS",
  26: "OPTIONS_END",
  27: "NAME",
  28: "OPTION_STRING_VALUE",
  29: "OPTION_VALUE",
  30: "PARSE_PARAM",
  31: "PARSER_TYPE",
  32: "LEFT",
  33: "RIGHT",
  34: "NONASSOC",
  35: "TOKEN_TYPE",
  36: "INTEGER",
  37: "EPSILON",
  38: "ALIAS",
  39: "PREC",
  40: "ARROW_ACTION",
  41: "ACTION_BODY",
  42: "INCLUDE",
  43: "PATH",
  44: "CODE"
},
TERROR: 2,
EOF: 1,

// internals: defined here so the object *structure* doesn't get modified by parse() et al,
// thus helping JIT compilers like Chrome V8.
originalQuoteName: null,
originalParseError: null,
cleanupAfterParse: null,
constructParseErrorInfo: null,

__reentrant_call_depth: 0,      // INTERNAL USE ONLY
__error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

// APIs which will be set up depending on user action code analysis:
//yyRecovering: 0,
//yyErrOk: 0,
//yyClearIn: 0,

// Helper APIs
// -----------

// Helper function which can be overridden by user code later on: put suitable quotes around
// literal IDs in a description string.
quoteName: function parser_quoteName(id_str) {
    return '"' + id_str + '"';
},

// Return a more-or-less human-readable description of the given symbol, when available,
// or the symbol itself, serving as its own 'description' for lack of something better to serve up.
//
// Return NULL when the symbol is unknown to the parser.
describeSymbol: function parser_describeSymbol(symbol) {
    if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
        return this.terminal_descriptions_[symbol];
    }
    else if (symbol === this.EOF) {
        return 'end of input';
    }
    else if (this.terminals_[symbol]) {
        return this.quoteName(this.terminals_[symbol]);
    }
    // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
    //
    // An example of this may be where a rule's action code contains a call like this:
    //
    //      parser.describeSymbol(#$)
    //
    // to obtain a human-readable description or name of the current grammar rule. This comes handy in
    // error handling action code blocks, for example.
    var s = this.symbols_;
    for (var key in s) {
        if (s[key] === symbol) {
            return key;
        }
    }
    return null;
},

// Produce a (more or less) human-readable list of expected tokens at the point of failure.
//
// The produced list may contain token or token set descriptions instead of the tokens
// themselves to help turning this output into something that easier to read by humans
// unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
// expected terminals and nonterminals is produced.
//
// The returned list (array) will not contain any duplicate entries.
collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
    var TERROR = this.TERROR;
    var tokenset = [];
    var check = {};
    // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
    // If so, use that one instead of the less palatable token set.
    if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
        return [
            this.state_descriptions_[state]
        ];
    }
    for (var p in this.table[state]) {
        p = +p;
        if (p !== TERROR) {
            var d = do_not_describe ? p : this.describeSymbol(p);
            if (d && !check[d]) {
                tokenset.push(d);
                check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
            }
        }
    }
    return tokenset;
},
productions_: bp({
  pop: u([
  s,
  [45, 3],
  46,
  46,
  s,
  [47, 3],
  48,
  48,
  s,
  [49, 16],
  50,
  50,
  51,
  51,
  52,
  53,
  53,
  s,
  [54, 4],
  s,
  [55, 4, 1],
  58,
  58,
  59,
  59,
  60,
  60,
  s,
  [61, 3],
  62,
  s,
  [62, 4, 1],
  65,
  66,
  67,
  67,
  68,
  69,
  69,
  70,
  70,
  71,
  71,
  72,
  72,
  73,
  73,
  s,
  [74, 4],
  s,
  [75, 4],
  76,
  76,
  77,
  77,
  78,
  s,
  [79, 5],
  80,
  80,
  s,
  [81, 5],
  82,
  82,
  83,
  83,
  84,
  84,
  85,
  85,
  86,
  86
]),
  rule: u([
  5,
  5,
  3,
  0,
  2,
  0,
  s,
  [2, 3],
  0,
  2,
  1,
  1,
  c,
  [3, 3],
  s,
  [1, 5],
  s,
  [3, 5],
  c,
  [9, 5],
  c,
  [18, 3],
  s,
  [3, 3],
  s,
  [2, 3],
  s,
  [1, 3],
  2,
  1,
  2,
  2,
  c,
  [11, 3],
  0,
  c,
  [11, 7],
  1,
  4,
  3,
  c,
  [32, 3],
  2,
  0,
  c,
  [6, 4],
  c,
  [38, 4],
  c,
  [24, 5],
  c,
  [5, 4],
  c,
  [59, 6],
  0,
  0,
  1,
  5,
  4,
  4,
  c,
  [42, 3],
  c,
  [36, 3],
  c,
  [6, 3],
  0
])
}),
performAction: function parser__PerformAction(yyloc, yystate /* action[1] */, yysp, yyvstack, yylstack) {
/* this == yyval */
var yy = this.yy;

switch (yystate) {
case 1:
    /*! Production::    spec : declaration_list "%%" grammar optional_end_block EOF */
    this.$ = yyvstack[yysp - 4];
    if (yyvstack[yysp - 1] && yyvstack[yysp - 1].trim() !== '') {
        yy.addDeclaration(this.$, { include: yyvstack[yysp - 1] });
    }
    return extend(this.$, yyvstack[yysp - 2]);
    break;

case 2:
    /*! Production::    spec : declaration_list "%%" grammar error EOF */
    yy.parser.yyError("Maybe you did not correctly separate trailing code from the grammar rule set with a '%%' marker on an otherwise empty line?");
    break;

case 3:
    /*! Production::    spec : declaration_list error EOF */
    yy.parser.yyError("Maybe you did not correctly separate the parse 'header section' (token definitions, options, lexer spec, etc.) from the grammar rule set with a '%%' on an otherwise empty line?");
    break;

case 5:
    /*! Production::    optional_end_block : "%%" extra_parser_module_code */
case 38:
    /*! Production::    parse_params : PARSE_PARAM token_list */
case 39:
    /*! Production::    parser_type : PARSER_TYPE symbol */
case 71:
    /*! Production::    expression : ID */
case 81:
    /*! Production::    symbol : id */
case 82:
    /*! Production::    symbol : STRING */
case 83:
    /*! Production::    id : ID */
case 86:
    /*! Production::    action_ne : ACTION */
case 87:
    /*! Production::    action_ne : include_macro_code */
case 89:
    /*! Production::    action : action_ne */
case 92:
    /*! Production::    action_body : action_comments_body */
case 96:
    /*! Production::    action_comments_body : ACTION_BODY */
case 98:
    /*! Production::    extra_parser_module_code : optional_module_code_chunk */
case 102:
    /*! Production::    module_code_chunk : CODE */
case 104:
    /*! Production::    optional_module_code_chunk : module_code_chunk */
    this.$ = yyvstack[yysp];
    break;

case 6:
    /*! Production::    optional_action_header_block : ε */
case 10:
    /*! Production::    declaration_list : ε */
    this.$ = {};
    break;

case 7:
    /*! Production::    optional_action_header_block : optional_action_header_block ACTION */
case 8:
    /*! Production::    optional_action_header_block : optional_action_header_block include_macro_code */
    this.$ = yyvstack[yysp - 1];
    yy.addDeclaration(this.$, { actionInclude: yyvstack[yysp] });
    break;

case 9:
    /*! Production::    declaration_list : declaration_list declaration */
    this.$ = yyvstack[yysp - 1]; yy.addDeclaration(this.$, yyvstack[yysp]);
    break;

case 11:
    /*! Production::    declaration : START id */
    this.$ = {start: yyvstack[yysp]};
    break;

case 12:
    /*! Production::    declaration : LEX_BLOCK */
    this.$ = {lex: {text: yyvstack[yysp], position: yylstack[yysp]}};
    break;

case 13:
    /*! Production::    declaration : operator */
    this.$ = {operator: yyvstack[yysp]};
    break;

case 14:
    /*! Production::    declaration : TOKEN full_token_definitions */
    this.$ = {token_list: yyvstack[yysp]};
    break;

case 15:
    /*! Production::    declaration : ACTION */
case 16:
    /*! Production::    declaration : include_macro_code */
    this.$ = {include: yyvstack[yysp]};
    break;

case 17:
    /*! Production::    declaration : parse_params */
    this.$ = {parseParams: yyvstack[yysp]};
    break;

case 18:
    /*! Production::    declaration : parser_type */
    this.$ = {parserType: yyvstack[yysp]};
    break;

case 19:
    /*! Production::    declaration : options */
    this.$ = {options: yyvstack[yysp]};
    break;

case 20:
    /*! Production::    declaration : DEBUG */
    this.$ = {options: [['debug', true]]};
    break;

case 21:
    /*! Production::    declaration : UNKNOWN_DECL */
    this.$ = {unknownDecl: yyvstack[yysp]};
    break;

case 22:
    /*! Production::    declaration : IMPORT import_name import_path */
    this.$ = {imports: {name: yyvstack[yysp - 1], path: yyvstack[yysp]}};
    break;

case 23:
    /*! Production::    declaration : IMPORT import_name error */
    yy.parser.yyError("You did not specify a legal file path for the '%import' initialization code statement, which must have the format: '%import qualifier_name file_path'.");
    break;

case 24:
    /*! Production::    declaration : IMPORT error import_path */
    yy.parser.yyError("Each '%import'-ed initialization code section must be qualified by a name, e.g. 'required' before the import path itself: '%import qualifier_name file_path'.");
    break;

case 25:
    /*! Production::    declaration : INIT_CODE import_name action_ne */
    this.$ = {initCode: {qualifier: yyvstack[yysp - 1], include: yyvstack[yysp]}};
    break;

case 26:
    /*! Production::    declaration : INIT_CODE error action_ne */
    yy.parser.yyError("Each '%code' initialization code section must be qualified by a name, e.g. 'required' before the action code itself: '%code qualifier_name {action code}'.");
    break;

case 31:
    /*! Production::    options : OPTIONS option_list OPTIONS_END */
case 84:
    /*! Production::    action_ne : "{" action_body "}" */
    this.$ = yyvstack[yysp - 1];
    break;

case 32:
    /*! Production::    option_list : option_list option */
case 44:
    /*! Production::    token_list : token_list symbol */
case 55:
    /*! Production::    id_list : id_list id */
    this.$ = yyvstack[yysp - 1]; this.$.push(yyvstack[yysp]);
    break;

case 33:
    /*! Production::    option_list : option */
case 45:
    /*! Production::    token_list : symbol */
case 56:
    /*! Production::    id_list : id */
case 62:
    /*! Production::    handle_list : handle_action */
    this.$ = [yyvstack[yysp]];
    break;

case 34:
    /*! Production::    option : NAME */
    this.$ = [yyvstack[yysp], true];
    break;

case 35:
    /*! Production::    option : NAME "=" OPTION_STRING_VALUE */
    this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
    break;

case 36:
    /*! Production::    option : NAME "=" OPTION_VALUE */
case 37:
    /*! Production::    option : NAME "=" NAME */
    this.$ = [yyvstack[yysp - 2], parseValue(yyvstack[yysp])];
    break;

case 40:
    /*! Production::    operator : associativity token_list */
    this.$ = [yyvstack[yysp - 1]]; this.$.push.apply(this.$, yyvstack[yysp]);
    break;

case 41:
    /*! Production::    associativity : LEFT */
    this.$ = 'left';
    break;

case 42:
    /*! Production::    associativity : RIGHT */
    this.$ = 'right';
    break;

case 43:
    /*! Production::    associativity : NONASSOC */
    this.$ = 'nonassoc';
    break;

case 46:
    /*! Production::    full_token_definitions : optional_token_type id_list */
    var rv = [];
    var lst = yyvstack[yysp];
    for (var i = 0, len = lst.length; i < len; i++) {
        var id = lst[i];
        var m = {id: id};
        if (yyvstack[yysp - 1]) {
            m.type = yyvstack[yysp - 1];
        }
        rv.push(m);
    }
    this.$ = rv;
    break;

case 47:
    /*! Production::    full_token_definitions : optional_token_type one_full_token */
    var m = yyvstack[yysp];
    if (yyvstack[yysp - 1]) {
        m.type = yyvstack[yysp - 1];
    }
    this.$ = [m];
    break;

case 48:
    /*! Production::    one_full_token : id token_value token_description */
    this.$ = {
        id: yyvstack[yysp - 2],
        value: yyvstack[yysp - 1]
    };
    break;

case 49:
    /*! Production::    one_full_token : id token_description */
    this.$ = {
        id: yyvstack[yysp - 1],
        description: yyvstack[yysp]
    };
    break;

case 50:
    /*! Production::    one_full_token : id token_value */
    this.$ = {
        id: yyvstack[yysp - 1],
        value: yyvstack[yysp],
        description: $token_description
    };
    break;

case 51:
    /*! Production::    optional_token_type : ε */
    this.$ = false;
    break;

case 57:
    /*! Production::    grammar : optional_action_header_block production_list */
    this.$ = yyvstack[yysp - 1];
    this.$.grammar = yyvstack[yysp];
    break;

case 58:
    /*! Production::    production_list : production_list production */
    this.$ = yyvstack[yysp - 1];
    if (yyvstack[yysp][0] in this.$) {
        this.$[yyvstack[yysp][0]] = this.$[yyvstack[yysp][0]].concat(yyvstack[yysp][1]);
    } else {
        this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
    }
    break;

case 59:
    /*! Production::    production_list : production */
    this.$ = {}; this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
    break;

case 60:
    /*! Production::    production : id ":" handle_list ";" */
    this.$ = [yyvstack[yysp - 3], yyvstack[yysp - 1]];
    break;

case 61:
    /*! Production::    handle_list : handle_list "|" handle_action */
    this.$ = yyvstack[yysp - 2];
    this.$.push(yyvstack[yysp]);
    break;

case 63:
    /*! Production::    handle_action : handle prec action */
    this.$ = [(yyvstack[yysp - 2].length ? yyvstack[yysp - 2].join(' ') : '')];
    if (yyvstack[yysp]) {
        this.$.push(yyvstack[yysp]);
    }
    if (yyvstack[yysp - 1]) {
        if (yyvstack[yysp - 2].length === 0) {
            yy.parser.yyError('You cannot specify a precedence override for an epsilon (a.k.a. empty) rule!');
        }
        this.$.push(yyvstack[yysp - 1]);
    }
    if (this.$.length === 1) {
        this.$ = this.$[0];
    }
    break;

case 64:
    /*! Production::    handle_action : EPSILON action */
    this.$ = [''];
    if (yyvstack[yysp]) {
        this.$.push(yyvstack[yysp]);
    }
    if (this.$.length === 1) {
        this.$ = this.$[0];
    }
    break;

case 65:
    /*! Production::    handle : handle suffixed_expression */
    this.$ = yyvstack[yysp - 1];
    this.$.push(yyvstack[yysp]);
    break;

case 66:
    /*! Production::    handle : ε */
    this.$ = [];
    break;

case 67:
    /*! Production::    handle_sublist : handle_sublist "|" handle */
    this.$ = yyvstack[yysp - 2];
    this.$.push(yyvstack[yysp].join(' '));
    break;

case 68:
    /*! Production::    handle_sublist : handle */
    this.$ = [yyvstack[yysp].join(' ')];
    break;

case 69:
    /*! Production::    suffixed_expression : expression suffix ALIAS */
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + "[" + yyvstack[yysp] + "]";
    break;

case 70:
    /*! Production::    suffixed_expression : expression suffix */
case 97:
    /*! Production::    action_comments_body : action_comments_body ACTION_BODY */
case 103:
    /*! Production::    module_code_chunk : module_code_chunk CODE */
    this.$ = yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 72:
    /*! Production::    expression : STRING */
    // Re-encode the string *anyway* as it will
    // be made part of the rule rhs a.k.a. production (type: *string*) again and we want
    // to be able to handle all tokens, including *significant space*
    // encoded as literal tokens in a grammar such as this: `rule: A ' ' B`.
    if (yyvstack[yysp].indexOf("'") >= 0) {
        this.$ = '"' + yyvstack[yysp] + '"';
    } else {
        this.$ = "'" + yyvstack[yysp] + "'";
    }
    break;

case 73:
    /*! Production::    expression : "(" handle_sublist ")" */
    this.$ = '(' + yyvstack[yysp - 1].join(' | ') + ')';
    break;

case 74:
    /*! Production::    expression : "(" handle_sublist error */
    var l = yyvstack[yysp - 1];
    var ab = l.slice(0, 10).join(' | ');
    yy.parser.yyError("Seems you did not correctly bracket a grammar rule sublist in '( ... )' brackets. Offending handle sublist:\n" + ab);
    break;

case 75:
    /*! Production::    suffix : ε */
case 90:
    /*! Production::    action : ε */
case 91:
    /*! Production::    action_body : ε */
case 105:
    /*! Production::    optional_module_code_chunk : ε */
    this.$ = '';
    break;

case 79:
    /*! Production::    prec : PREC symbol */
    this.$ = { prec: yyvstack[yysp] };
    break;

case 80:
    /*! Production::    prec : ε */
    this.$ = null;
    break;

case 85:
    /*! Production::    action_ne : "{" action_body error */
    var l = yyvstack[yysp - 1].split('\n');
    var ab = l.slice(0, 10).join('\n');
    yy.parser.yyError("Seems you did not correctly bracket a parser rule action block in curly braces: '{ ... }'. Offending action body:\n" + ab);
    break;

case 88:
    /*! Production::    action_ne : ARROW_ACTION */
    this.$ = '$$ = ' + yyvstack[yysp];
    break;

case 93:
    /*! Production::    action_body : action_body "{" action_body "}" action_comments_body */
    this.$ = yyvstack[yysp - 4] + yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 94:
    /*! Production::    action_body : action_body "{" action_body "}" */
    this.$ = yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 95:
    /*! Production::    action_body : action_body "{" action_body error */
    var l = yyvstack[yysp - 1].split('\n');
    var ab = l.slice(0, 10).join('\n');
    yy.parser.yyError("Seems you did not correctly match curly braces '{ ... }' in a parser rule action block. Offending action body part:\n" + ab);
    break;

case 99:
    /*! Production::    extra_parser_module_code : optional_module_code_chunk include_macro_code extra_parser_module_code */
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 100:
    /*! Production::    include_macro_code : INCLUDE PATH */
    var fs = require('fs');
    var fileContent = fs.readFileSync(yyvstack[yysp], { encoding: 'utf-8' });
    // And no, we don't support nested '%include':
    this.$ = '\n// Included by Jison: ' + yyvstack[yysp] + ':\n\n' + fileContent + '\n\n// End Of Include by Jison: ' + yyvstack[yysp] + '\n\n';
    break;

case 101:
    /*! Production::    include_macro_code : INCLUDE error */
    yy.parser.yyError("%include MUST be followed by a valid file path");
    break;

}
},
table: bt({
  len: u([
  19,
  1,
  24,
  5,
  1,
  17,
  2,
  17,
  17,
  4,
  s,
  [17, 7],
  4,
  4,
  5,
  2,
  s,
  [5, 4, -1],
  2,
  2,
  4,
  7,
  1,
  17,
  25,
  17,
  4,
  1,
  4,
  3,
  7,
  7,
  6,
  6,
  21,
  19,
  23,
  23,
  22,
  22,
  21,
  17,
  3,
  2,
  3,
  1,
  1,
  6,
  6,
  3,
  3,
  4,
  1,
  19,
  17,
  22,
  s,
  [17, 6],
  6,
  s,
  [19, 3],
  17,
  19,
  17,
  c,
  [26, 4],
  1,
  s,
  [3, 3],
  4,
  14,
  18,
  19,
  17,
  18,
  17,
  3,
  4,
  4,
  s,
  [2, 3],
  6,
  c,
  [75, 3],
  13,
  9,
  17,
  19,
  19,
  6,
  c,
  [74, 3],
  13,
  9,
  12,
  4,
  17,
  16,
  16,
  8,
  2,
  2,
  c,
  [22, 3],
  6,
  s,
  [13, 4],
  3,
  8,
  5,
  3,
  12,
  16,
  16,
  7,
  4,
  8
]),
  symbol: u([
  2,
  s,
  [14, 9, 1],
  25,
  s,
  [30, 5, 1],
  42,
  45,
  48,
  1,
  c,
  [20, 17],
  49,
  52,
  s,
  [55, 4, 1],
  84,
  15,
  23,
  42,
  47,
  66,
  c,
  [30, 18],
  23,
  78,
  c,
  [19, 17],
  c,
  [36, 18],
  35,
  60,
  62,
  c,
  [38, 34],
  c,
  [17, 86],
  23,
  24,
  50,
  c,
  [4, 4],
  23,
  24,
  59,
  77,
  78,
  2,
  43,
  c,
  [7, 5],
  23,
  24,
  77,
  78,
  27,
  53,
  54,
  23,
  24,
  23,
  24,
  23,
  24,
  c,
  [210, 3],
  46,
  c,
  [219, 3],
  67,
  68,
  78,
  84,
  c,
  [221, 18],
  2,
  4,
  5,
  6,
  12,
  s,
  [14, 12, 1],
  c,
  [23, 5],
  36,
  40,
  c,
  [227, 19],
  61,
  65,
  78,
  23,
  c,
  [105, 3],
  51,
  c,
  [3, 3],
  2,
  12,
  15,
  23,
  24,
  c,
  [36, 3],
  c,
  [7, 6],
  12,
  15,
  40,
  42,
  79,
  84,
  c,
  [6, 6],
  c,
  [55, 10],
  c,
  [76, 8],
  42,
  c,
  [150, 3],
  c,
  [21, 18],
  2,
  c,
  [119, 20],
  c,
  [82, 3],
  c,
  [23, 22],
  1,
  c,
  [24, 3],
  c,
  [23, 10],
  c,
  [67, 7],
  44,
  c,
  [22, 22],
  c,
  [130, 31],
  c,
  [19, 7],
  26,
  27,
  54,
  26,
  27,
  3,
  26,
  27,
  s,
  [1, 3],
  42,
  44,
  83,
  85,
  86,
  c,
  [282, 3],
  23,
  68,
  78,
  c,
  [295, 3],
  c,
  [3, 3],
  c,
  [12, 4],
  4,
  c,
  [71, 11],
  c,
  [51, 7],
  c,
  [519, 28],
  c,
  [313, 9],
  42,
  63,
  64,
  c,
  [503, 103],
  12,
  13,
  41,
  81,
  82,
  c,
  [258, 12],
  c,
  [346, 10],
  c,
  [19, 36],
  c,
  [204, 34],
  c,
  [36, 18],
  26,
  27,
  27,
  28,
  29,
  s,
  [1, 4],
  42,
  84,
  c,
  [310, 3],
  c,
  [3, 4],
  c,
  [298, 3],
  5,
  6,
  7,
  c,
  [519, 4],
  37,
  39,
  40,
  42,
  69,
  70,
  71,
  c,
  [311, 18],
  c,
  [18, 10],
  c,
  [88, 8],
  c,
  [290, 28],
  c,
  [124, 25],
  c,
  [240, 3],
  c,
  [243, 4],
  c,
  [4, 4],
  26,
  27,
  26,
  27,
  c,
  [442, 3],
  c,
  [440, 6],
  42,
  44,
  5,
  6,
  5,
  6,
  c,
  [133, 7],
  c,
  [132, 3],
  73,
  74,
  76,
  c,
  [580, 3],
  c,
  [652, 4],
  80,
  c,
  [653, 11],
  c,
  [284, 46],
  c,
  [347, 6],
  c,
  [6, 3],
  1,
  c,
  [225, 15],
  70,
  71,
  c,
  [92, 10],
  s,
  [5, 4, 1],
  c,
  [116, 7],
  c,
  [879, 4],
  c,
  [16, 5],
  s,
  [9, 4, 1],
  c,
  [19, 3],
  38,
  c,
  [20, 3],
  75,
  c,
  [17, 16],
  c,
  [16, 17],
  c,
  [15, 3],
  23,
  24,
  71,
  72,
  c,
  [189, 4],
  c,
  [108, 3],
  c,
  [198, 6],
  c,
  [93, 4],
  c,
  [90, 9],
  c,
  [54, 9],
  c,
  [13, 35],
  6,
  8,
  c,
  [80, 6],
  73,
  74,
  c,
  [184, 4],
  c,
  [189, 4],
  c,
  [161, 12],
  c,
  [140, 39],
  c,
  [353, 5],
  c,
  [71, 7]
]),
  type: u([
  s,
  [2, 17],
  0,
  0,
  1,
  c,
  [20, 19],
  s,
  [0, 5],
  c,
  [10, 5],
  s,
  [2, 19],
  c,
  [20, 20],
  c,
  [68, 19],
  s,
  [2, 122],
  c,
  [186, 5],
  c,
  [199, 5],
  c,
  [206, 7],
  c,
  [143, 5],
  c,
  [146, 11],
  c,
  [219, 6],
  c,
  [163, 63],
  c,
  [95, 8],
  c,
  [273, 21],
  c,
  [123, 8],
  c,
  [282, 143],
  c,
  [130, 27],
  c,
  [20, 11],
  c,
  [313, 9],
  c,
  [358, 33],
  c,
  [520, 142],
  c,
  [346, 122],
  c,
  [121, 22],
  c,
  [610, 39],
  c,
  [182, 73],
  c,
  [112, 20],
  c,
  [20, 9],
  c,
  [751, 62],
  c,
  [61, 22],
  c,
  [92, 25],
  c,
  [47, 18],
  c,
  [125, 39],
  c,
  [451, 80],
  c,
  [932, 9],
  c,
  [469, 62],
  0,
  0
]),
  state: u([
  1,
  2,
  5,
  14,
  12,
  13,
  8,
  19,
  11,
  28,
  27,
  30,
  32,
  33,
  35,
  39,
  41,
  42,
  43,
  47,
  42,
  43,
  48,
  43,
  49,
  50,
  52,
  55,
  58,
  59,
  57,
  61,
  60,
  62,
  63,
  67,
  68,
  71,
  73,
  71,
  74,
  43,
  74,
  43,
  76,
  80,
  82,
  81,
  84,
  59,
  86,
  87,
  88,
  91,
  92,
  97,
  99,
  100,
  101,
  103,
  108,
  82,
  81,
  112,
  114,
  111,
  119,
  118,
  71,
  120,
  92,
  121,
  101,
  119,
  122,
  71,
  123,
  43,
  124,
  129,
  128,
  112,
  114,
  136,
  137,
  112,
  114
]),
  mode: u([
  s,
  [2, 17],
  s,
  [1, 17],
  c,
  [20, 4],
  c,
  [38, 18],
  s,
  [2, 35],
  c,
  [36, 36],
  s,
  [2, 84],
  c,
  [192, 18],
  c,
  [22, 9],
  c,
  [87, 61],
  c,
  [67, 20],
  c,
  [101, 15],
  c,
  [18, 5],
  s,
  [2, 126],
  c,
  [128, 26],
  c,
  [26, 4],
  c,
  [3, 4],
  c,
  [7, 6],
  c,
  [415, 12],
  c,
  [11, 22],
  c,
  [473, 32],
  c,
  [233, 107],
  c,
  [340, 113],
  c,
  [467, 7],
  c,
  [299, 7],
  c,
  [138, 43],
  c,
  [170, 60],
  c,
  [877, 19],
  c,
  [17, 5],
  c,
  [139, 9],
  c,
  [10, 7],
  c,
  [713, 61],
  c,
  [59, 17],
  c,
  [17, 6],
  c,
  [85, 16],
  c,
  [14, 7],
  c,
  [107, 53],
  c,
  [53, 22],
  c,
  [73, 43],
  c,
  [65, 5],
  c,
  [880, 4],
  c,
  [337, 60],
  c,
  [67, 7]
]),
  goto: u([
  s,
  [10, 17],
  4,
  3,
  10,
  6,
  7,
  9,
  s,
  [15, 4, 1],
  23,
  21,
  22,
  24,
  25,
  26,
  20,
  s,
  [6, 3],
  29,
  s,
  [9, 17],
  31,
  s,
  [12, 17],
  s,
  [13, 17],
  51,
  34,
  s,
  [15, 17],
  s,
  [16, 17],
  s,
  [17, 17],
  s,
  [18, 17],
  s,
  [19, 17],
  s,
  [20, 17],
  s,
  [21, 17],
  36,
  37,
  38,
  40,
  37,
  38,
  31,
  44,
  46,
  45,
  31,
  44,
  31,
  44,
  51,
  41,
  41,
  42,
  42,
  43,
  43,
  4,
  53,
  54,
  56,
  31,
  20,
  3,
  s,
  [11, 17],
  s,
  [83, 25],
  s,
  [14, 17],
  31,
  52,
  64,
  65,
  66,
  65,
  66,
  s,
  [27, 7],
  s,
  [28, 7],
  69,
  70,
  72,
  20,
  c,
  [4, 4],
  s,
  [40, 10],
  31,
  44,
  s,
  [40, 7],
  s,
  [45, 19],
  s,
  [81, 23],
  s,
  [82, 23],
  s,
  [100, 22],
  s,
  [101, 22],
  s,
  [38, 10],
  31,
  44,
  s,
  [38, 7],
  s,
  [39, 17],
  75,
  51,
  33,
  33,
  77,
  34,
  34,
  78,
  79,
  105,
  105,
  83,
  s,
  [57, 3],
  31,
  s,
  [7, 3],
  s,
  [8, 3],
  s,
  [59, 4],
  85,
  s,
  [46, 10],
  31,
  s,
  [46, 7],
  s,
  [47, 17],
  s,
  [56, 11],
  90,
  s,
  [56, 6],
  89,
  56,
  s,
  [22, 17],
  s,
  [23, 17],
  s,
  [29, 17],
  s,
  [30, 17],
  s,
  [24, 17],
  s,
  [25, 17],
  s,
  [91, 3],
  93,
  s,
  [86, 19],
  s,
  [87, 19],
  s,
  [88, 19],
  s,
  [26, 17],
  s,
  [44, 19],
  s,
  [31, 17],
  32,
  32,
  96,
  94,
  95,
  1,
  2,
  5,
  98,
  20,
  104,
  104,
  98,
  s,
  [102, 3],
  s,
  [58, 4],
  s,
  [66, 7],
  102,
  s,
  [66, 3],
  s,
  [55, 18],
  s,
  [50, 10],
  90,
  s,
  [50, 7],
  s,
  [49, 17],
  s,
  [53, 18],
  s,
  [54, 17],
  105,
  106,
  104,
  s,
  [92, 3],
  107,
  s,
  [96, 4],
  35,
  35,
  36,
  36,
  37,
  37,
  c,
  [425, 3],
  s,
  [103, 3],
  109,
  110,
  62,
  62,
  80,
  80,
  117,
  80,
  80,
  115,
  116,
  113,
  80,
  80,
  90,
  90,
  c,
  [624, 4],
  s,
  [48, 17],
  s,
  [84, 19],
  s,
  [85, 19],
  c,
  [331, 4],
  s,
  [97, 4],
  99,
  s,
  [60, 4],
  c,
  [210, 11],
  c,
  [85, 6],
  s,
  [65, 12],
  31,
  44,
  s,
  [75, 5],
  125,
  126,
  127,
  s,
  [75, 8],
  s,
  [71, 16],
  s,
  [72, 16],
  s,
  [66, 6],
  64,
  64,
  89,
  89,
  131,
  106,
  130,
  61,
  61,
  63,
  63,
  s,
  [79, 6],
  s,
  [70, 9],
  132,
  s,
  [70, 3],
  s,
  [76, 13],
  s,
  [77, 13],
  s,
  [78, 13],
  134,
  135,
  133,
  68,
  68,
  117,
  68,
  115,
  116,
  s,
  [94, 3],
  93,
  s,
  [95, 3],
  s,
  [69, 12],
  s,
  [73, 16],
  s,
  [74, 16],
  s,
  [66, 6],
  s,
  [93, 3],
  107,
  67,
  67,
  117,
  67,
  115,
  116
])
}),
defaultActions: bda({
  idx: u([
  0,
  3,
  5,
  7,
  8,
  s,
  [10, 7, 1],
  24,
  25,
  26,
  s,
  [29, 4, 1],
  34,
  37,
  38,
  s,
  [42, 5, 1],
  48,
  50,
  56,
  57,
  58,
  61,
  s,
  [63, 6, 1],
  s,
  [70, 7, 1],
  78,
  79,
  80,
  83,
  84,
  86,
  88,
  89,
  90,
  s,
  [93, 4, 1],
  98,
  100,
  103,
  104,
  105,
  107,
  108,
  109,
  112,
  s,
  [115, 5, 1],
  121,
  122,
  123,
  125,
  126,
  127,
  s,
  [131, 5, 1]
]),
  goto: u([
  10,
  6,
  9,
  12,
  13,
  s,
  [15, 7, 1],
  41,
  42,
  43,
  3,
  11,
  83,
  14,
  52,
  27,
  28,
  45,
  81,
  82,
  100,
  101,
  39,
  33,
  7,
  8,
  59,
  47,
  22,
  23,
  29,
  30,
  24,
  25,
  86,
  87,
  88,
  26,
  44,
  31,
  32,
  1,
  2,
  5,
  102,
  58,
  55,
  49,
  53,
  54,
  96,
  35,
  36,
  37,
  103,
  62,
  48,
  84,
  85,
  97,
  99,
  60,
  65,
  71,
  72,
  66,
  64,
  89,
  61,
  63,
  79,
  76,
  77,
  78,
  95,
  69,
  73,
  74,
  66
])
}),
parseError: function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable && typeof this.trace === 'function') {
        this.trace(str);
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
},
parse: function parse(input) {
    var self = this,
        stack = new Array(128),         // token stack: stores token which leads to state at the same index (column storage)
        sstack = new Array(128),        // state stack: stores states (column storage)

        vstack = new Array(128),        // semantic value stack
        lstack = new Array(128),        // location stack
        table = this.table,
        sp = 0;                         // 'stack pointer': index into the stacks

    var recovering = 0;                 // (only used when the grammar contains error recovery rules)
    var TERROR = this.TERROR,
        EOF = this.EOF,
        ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    var NO_ACTION = [0, table.length /* ensures that anyone using this new state will fail dramatically! */];

    //this.reductionCount = this.shiftCount = 0;

    var lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    var sharedState_yy = {
        parseError: null,
        quoteName: null,
        lexer: null,
        parser: null,
        pre_parse: null,
        post_parse: null
    };
    // copy state
    for (var k in this.yy) {
      if (Object.prototype.hasOwnProperty.call(this.yy, k)) {
        sharedState_yy[k] = this.yy[k];
      }
    }

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;



















    // *Always* setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions as it is paramount
    // to have *their* closure match ours -- if we only set them up once,
    // any subsequent `parse()` runs will fail in very obscure ways when
    // these functions are invoked in the user action code block(s) as
    // their closure will still refer to the `parse()` instance which set
    // them up. Hence we MUST set them up at the start of every `parse()` run!
    if (this.yyError) {
        this.yyError = function yyError(str /*, ...args */) {



            var error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
            var expected = this.collect_expected_token_set(state);
            var hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));


            // Add any extra args to the hash under the name `extra_error_attributes`:
            var args = Array.prototype.slice.call(arguments, 1);
            if (args.length) {
                hash.extra_error_attributes = args;
            }

            var r = this.parseError(str, hash, this.JisonParserError);
            return r;
        };
    }






    lexer.setInput(input, sharedState_yy);

    var yyloc = lexer.yylloc || {};
    lstack[sp] = yyloc;
    vstack[sp] = null;
    sstack[sp] = 0;
    stack[sp] = 0;
    ++sp;





    var ranges = lexer.options && lexer.options.ranges;

    // Does the shared state override the default `parseError` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError(str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default `quoteName` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = sharedState_yy.quoteName;
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a `finally { ... }` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `sharedState`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        var rv;

        if (invoke_post_methods) {
            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.parseError = undefined;
            sharedState_yy.quoteName = undefined;
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;
        lstack.length = 0;
        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;
        }

        return resultValue;
    };

    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        var pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: lexer.yytext,
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,
            loc: lexer.yylloc || {},
            expected: expected,
            recoverable: recoverable,
            state: state,
            action: action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,
            location_stack: lstack,
            stack_pointer: sp,
            yy: sharedState_yy,
            lexer: lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };


    function lex() {
        var token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }
        return token || EOF;
    }


    var symbol = 0;
    var preErrorSymbol = 0;
    var lastEofErrorStateDepth = 0;
    var state, action, r, t;
    var yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    var p, len, this_production;
    var lstack_begin, lstack_end;
    var newState;
    var retval = false;


    // Return the rule stack depth where the nearest error rule can be found.
    // Return -1 when no error recovery rule was found.
    function locateNearestErrorRecoveryRule(state) {
        var stack_probe = sp - 1;
        var depth = 0;

        // try to recover from error
        for (;;) {
            // check for error recovery rule in this state

            var t = table[state][TERROR] || NO_ACTION;
            if (t[0]) {
                // We need to make sure we're not cycling forever:
                // once we hit EOF, even when we `yyerrok()` an error, we must
                // prevent the core from running forever,
                // e.g. when parent rules are still expecting certain input to
                // follow after this, for example when you handle an error inside a set
                // of braces which are matched by a parent rule in your grammar.
                //
                // Hence we require that every error handling/recovery attempt
                // *after we've hit EOF* has a diminishing state stack: this means
                // we will ultimately have unwound the state stack entirely and thus
                // terminate the parse in a controlled fashion even when we have
                // very complex error/recovery code interplay in the core + user
                // action code blocks:

                if (symbol === EOF) {
                    if (!lastEofErrorStateDepth) {
                        lastEofErrorStateDepth = sp - 1 - depth;
                    } else if (lastEofErrorStateDepth <= sp - 1 - depth) {

                        --stack_probe; // popStack(1): [symbol, action]
                        state = sstack[stack_probe];
                        ++depth;
                        continue;
                    }
                }
                return depth;
            }
            if (state === 0 /* $accept rule */ || stack_probe < 1) {

                return -1; // No suitable error recovery rule available.
            }
            --stack_probe; // popStack(1): [symbol, action]
            state = sstack[stack_probe];
            ++depth;
        }
    }


    try {
        this.__reentrant_call_depth++;

        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single `==` condition below covers both these `===` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];




                // handle parse error
                if (!action) {
                    // first see if there's any chance at hitting an error recovery rule:
                    var error_rule_depth = locateNearestErrorRecoveryRule(state);
                    var errStr = null;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    if (!recovering) {
                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                        } else {
                            errStr = 'Parse error: ';
                        }
                        if (lexer.showPosition) {
                            errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }
                        p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));
                        r = this.parseError(p.errStr, p, this.JisonParserError);


                        if (!p.recoverable) {
                            retval = r;
                            break;
                        } else {
                            // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                        }
                    }



                    // just recovered from another error
                    if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                        // only barf a fatal hairball when we're out of look-ahead symbols and none hit a match;
                        // this DOES discard look-ahead while recovering from an error when said look-ahead doesn't
                        // suit the error recovery rules... The error HAS been reported already so we're fine with
                        // throwing away a few items if that is what it takes to match the nearest recovery rule!
                        if (symbol === EOF || preErrorSymbol === EOF) {
                            p = this.__error_infos[this.__error_infos.length - 1];
                            if (!p) {
                                p = this.constructParseErrorInfo('Parsing halted while starting to recover from another error.', null, expected, false);
                            } else {
                                p.errStr = 'Parsing halted while starting to recover from another error. Previous error which resulted in this fatal result: ' + p.errStr;
                                p.recoverable = false;
                            }
                            retval = this.parseError(p.errStr, p, this.JisonParserError);
                            break;
                        }

                        // discard current lookahead and grab another



                        yyloc = lexer.yylloc || {};

                        symbol = lex();


                    }

                    // try to recover from error
                    if (error_rule_depth < 0) {
                        p = this.constructParseErrorInfo((errStr || 'Parsing halted. No suitable error recovery rule available.'), null, expected, false);
                        retval = this.parseError(p.errStr, p, this.JisonParserError);
                        break;
                    }
                    sp -= error_rule_depth;

                    preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                    symbol = TERROR;            // insert generic error symbol as new lookahead
                    // allow N (default: 3) real symbols to be shifted before reporting a new error
                    recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;

                    newState = sstack[sp - 1];



                    continue;
                }


            }









            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo(('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol), null, null, false);
                    retval = this.parseError(p.errStr, p, this.JisonParserError);
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                retval = this.parseError(p.errStr, p, this.JisonParserError);
                break;

            // shift:
            case 1:
                //this.shiftCount++;
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;
                lstack[sp] = lexer.yylloc || {};
                sstack[sp] = newState; // push state
                ++sp;
                symbol = 0;
                if (!preErrorSymbol) { // normal execution / no error
                    // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                    yyloc = lexer.yylloc || {};

                    if (recovering > 0) {
                        recovering--;

                    }
                } else {
                    // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                    symbol = preErrorSymbol;
                    preErrorSymbol = 0;

                    // read action for current state and first input
                    t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                    if (!t[0] || symbol === TERROR) {
                        // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                        // (simple) stuff might have been missing before the token which caused the error we're
                        // recovering from now...
                        //
                        // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                        // recovery, for then this we would we idling (cycling) on the error forever.
                        // Yes, this does not take into account the possibility that the *lexer* may have
                        // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!

                        symbol = 0;
                    }
                }

                continue;

            // reduce:
            case 2:
                //this.reductionCount++;
                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                len = this_production[1];
                lstack_end = sp;
                lstack_begin = lstack_end - (len || 1);
                lstack_end--;



                // Make sure subsequent `$$ = $1` default action doesn't fail
                // for rules where len==0 as then there's no $1 (you're reducing an epsilon rule then!)
                //
                // Also do this to prevent nasty action block codes to *read* `$0` or `$$`
                // and *not* get `undefined` as a result for their efforts!
                vstack[sp] = undefined;

                // perform semantic action
                yyval.$ = vstack[sp - len]; // default to $$ = $1; result must produce `undefined` when len == 0, as then there's no $1

                // default location, uses first token for firsts, last for lasts
                yyval._$ = {
                    first_line: lstack[lstack_begin].first_line,
                    last_line: lstack[lstack_end].last_line,
                    first_column: lstack[lstack_begin].first_column,
                    last_column: lstack[lstack_end].last_column
                };
                if (ranges) {
                    yyval._$.range = [lstack[lstack_begin].range[0], lstack[lstack_end].range[1]];
                }

                r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                if (typeof r !== 'undefined') {
                    retval = r;
                    break;
                }

                // pop off stack
                sp -= len;

                // don't overwrite the `symbol` variable: use a local var to speed things up:
                var ntsymbol = this_production[0];    // push nonterminal (reduce)
                stack[sp] = ntsymbol;
                vstack[sp] = yyval.$;
                lstack[sp] = yyval._$;
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[sstack[sp - 1]][ntsymbol];
                sstack[sp] = newState;
                ++sp;

                continue;

            // accept:
            case 3:
                retval = true;
                // Return the `$accept` rule's `$$` result, if available.
                //
                // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                // default, action):
                //
                //     $accept: <startSymbol> $end
                //                  %{ $$ = $1; @$ = @1; %}
                //
                // which, combined with the parse kernel's `$accept` state behaviour coded below,
                // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                //
                // In code:
                //
                //                  %{
                //                      @$ = @1;            // if location tracking support is included
                //                      if (typeof $1 !== 'undefined')
                //                          return $1;
                //                      else
                //                          return true;           // the default parse result if the rule actions don't produce anything
                //                  %}
                if (typeof yyval.$ !== 'undefined') {
                    retval = yyval.$;
                }
                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        }
        else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }
        else {
            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = this.parseError(p.errStr, p, this.JisonParserError);
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;
    }

    return retval;
},
yyError: 1
};
parser.originalParseError = parser.parseError;
parser.originalQuoteName = parser.quoteName;

var fs = require('fs');
var transform = require('./ebnf-transform').transform;
var ebnf = false;
var XRegExp = require('xregexp');       // for helping out the `%options xregexp` in the lexer


// transform ebnf to bnf if necessary
function extend(json, grammar) {
    json.bnf = ebnf ? transform(grammar.grammar) : grammar.grammar;
    if (grammar.actionInclude) {
        json.actionInclude = grammar.actionInclude;
    }
    return json;
}

// convert string value to number or boolean value, when possible
// (and when this is more or less obviously the intent)
// otherwise produce the string itself as value.
function parseValue(v) {
    if (v === 'false') {
        return false;
    }
    if (v === 'true') {
        return true;
    }
    // http://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number
    // Note that the `v` check ensures that we do not convert `undefined`, `null` and `''` (empty string!)
    if (v && !isNaN(v)) {
        var rv = +v;
        if (isFinite(rv)) {
            return rv;
        }
    }
    return v;
}
/* lexer generated by jison-lex 0.3.4-166 */
/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Lexer.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *               where `...` denotes the (optional) additional arguments the user passed to
 *               `lexer.lex(...)` and specified by way of `%parse-param ...` in the **parser** grammar file
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *               - `yy_`     : lexer instance reference used internally.
 *
 *               - `$avoiding_name_collisions`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *               - `...`     : the extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file and which are passed to the lexer via
 *                             its `lexer.lex(...)` API.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function([args...]),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **parser** grammar:
 *               these extra `args...` are passed verbatim to the lexer rules' action code.
 *
 *    cleanupAfterLex: function(do_not_nuke_errorinfos),
 *               Helper function.
 *               This helper API is invoked when the parse process has completed. This helper may
 *               be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *  
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


var lexer = (function () {
// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonLexerError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) { // V8
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
} else {
    JisonLexerError.prototype = Object.create(Error.prototype);
}
JisonLexerError.prototype.constructor = JisonLexerError;
JisonLexerError.prototype.name = 'JisonLexerError';




var lexer = {

    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   backtracking: .................... false
    //   location.ranges: ................. true
    //   location line+column tracking: ... true
    //
    //
    // Forwarded Parser Analysis flags:
    //
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses lexer values: ............... true / true
    //   location tracking: ............... true
    //   location assignment: ............. false
    //
    //
    // Lexer Analysis flags:
    //
    //   uses yyleng: ..................... undefined
    //   uses yylineno: ................... undefined
    //   uses yytext: ..................... undefined
    //   uses yylloc: ..................... undefined
    //   uses ParseError API: ............. undefined
    //   uses location tracking & editing:  undefined
    //   uses more() API: ................. undefined
    //   uses unput() API: ................ undefined
    //   uses reject() API: ............... undefined
    //   uses less() API: ................. undefined
    //   uses display APIs pastInput(), upcomingInput(), showPosition():
    //        ............................. undefined
    //   uses describeYYLLOC() API: ....... undefined
    //
    // --------- END OF REPORT -----------


    EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// <-- internal rule set cache for the current lexer state

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup

    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use

    done: false,                                /// INTERNAL USE ONLY
    _backtrack: false,                          /// INTERNAL USE ONLY
    _input: '',                                 /// INTERNAL USE ONLY
    _more: false,                               /// INTERNAL USE ONLY
    _signaled_error_token: false,               /// INTERNAL USE ONLY

    conditionStack: [],                         /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`

    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction

    /**
    INTERNAL USE: construct a suitable error info hash object instance for `parseError`.

    @public
    @this {RegExpLexer}
    */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable) {
        /** @constructor */
        var pei = {
            errStr: msg,
            recoverable: !!recoverable,
            text: this.match,           // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...
            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
            and make sure the error info doesn't stay due to potential
            ref cycle via userland code manipulations.
            These would otherwise all be memory leak opportunities!
            
            Note that only array and object references are nuked as those
            constitute the set of elements which can produce a cyclic ref.
            The rest of the members is kept intact as they are harmless.

            @public
            @this {LexErrorInfo}
            */
            destroy: function destructLexErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    },

    /**
    handler which is invoked when a lexer error occurs.

    @public
    @this {RegExpLexer}
    */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
        if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
        }
        if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
            return this.yy.parser.parseError(str, hash, ExceptionClass) || this.ERROR;
        } else if (typeof this.yy.parseError === 'function') {
            return this.yy.parseError(str, hash, ExceptionClass) || this.ERROR;
        } else {
            throw new ExceptionClass(str, hash);
        }
    },

    /**
    method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.

    @public
    @this {RegExpLexer}
    */
    yyerror: function yyError(str /*, ...args */) {
        var lineno_msg = '';
        if (this.options.trackPosition) {
            lineno_msg = ' on line ' + (this.yylineno + 1);
        }
        var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

        // Add any extra args to the hash under the name `extra_error_attributes`:
        var args = Array.prototype.slice.call(arguments, 1);
        if (args.length) {
            hash.extra_error_attributes = args;
        }

        return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
    },

    /**
    final cleanup function for when we have completed lexing the input;
    make it an API so that external code can use this one once userland
    code has decided it's time to destroy any lingering lexer error
    hash object instances and the like: this function helps to clean
    up these constructs, which *may* carry cyclic references which would
    otherwise prevent the instances from being properly and timely
    garbage-collected, i.e. this function helps prevent memory leaks!

    @public
    @this {RegExpLexer}
    */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
        var rv;

        // prevent lingering circular references from causing memory leaks:
        this.setInput('', {});

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;
        }

        return this;
    },

    /**
    clear the lexer token context; intended for internal use only

    @public
    @this {RegExpLexer}
    */
    clear: function lexer_clear() {
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        this.matches = false;
        this._more = false;
        this._backtrack = false;

        var col = this.yylloc ? this.yylloc.last_column : 0;
        this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,

            range: (this.options.ranges ? [this.offset, this.offset] : undefined)
        };
    },

    /**
    resets the lexer, sets new input

    @public
    @this {RegExpLexer}
    */
    setInput: function lexer_setInput(input, yy) {
        this.yy = yy || this.yy || {};

        // also check if we've fully initialized the lexer instance,
        // including expansion work to be done to go from a loaded
        // lexer to a usable lexer:
        if (!this.__decompressed) {
          // step 1: decompress the regex list:
          var rules = this.rules;
          for (var i = 0, len = rules.length; i < len; i++) {
            var rule_re = rules[i];

            // compression: is the RE an xref to another RE slot in the rules[] table?
            if (typeof rule_re === 'number') {
              rules[i] = rules[rule_re];
            }
          }

          // step 2: unfold the conditions[] set to make these ready for use:
          var conditions = this.conditions;
          for (var k in conditions) {
            var spec = conditions[k];

            var rule_ids = spec.rules;

            var len = rule_ids.length;
            var rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple!
            var rule_new_ids = new Array(len + 1);

            for (var i = 0; i < len; i++) {
              var idx = rule_ids[i];
              var rule_re = rules[idx];
              rule_regexes[i + 1] = rule_re;
              rule_new_ids[i + 1] = idx;
            }

            spec.rules = rule_new_ids;
            spec.__rule_regexes = rule_regexes;
            spec.__rule_count = len;
          }

          this.__decompressed = true;
        }

        this._input = input || '';
        this.clear();
        this._signaled_error_token = false;
        this.done = false;
        this.yylineno = 0;
        this.matched = '';
        this.conditionStack = ['INITIAL'];
        this.__currentRuleSet__ = null;
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: (this.options.ranges ? [0, 0] : undefined)
        };
        this.offset = 0;
        return this;
    },

    /**
    push a new input into the lexer and activate it:
    the old input position is stored and will be resumed
    once this new input has been consumed.

    Use this API to help implement C-preprocessor-like
    `#include` statements.

    Available options:

    - `emit_EOF_at_end` : {int} the `EOF`-like token to emit
                          when the new input is consumed: use
                          this to mark the end of the new input
                          in the parser grammar. zero/falsey
                          token value means no end marker token
                          will be emitted before the lexer
                          resumes reading from the previous input.

    @public
    @this {RegExpLexer}
    */
    pushInput: function lexer_pushInput(input, label, options) {
        options = options || {};

        this._input = input || '';
        this.clear();
        // this._signaled_error_token = false;
        this.done = false;
        this.yylineno = 0;
        this.matched = '';
        // this.conditionStack = ['INITIAL'];
        // this.__currentRuleSet__ = null;
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: (this.options.ranges ? [0, 0] : undefined)
        };
        this.offset = 0;
        return this;
    },

    /**
    consumes and returns one char from the input

    @public
    @this {RegExpLexer}
    */
    input: function lexer_input() {
        if (!this._input) {
            //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
        }
        var ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        // Count the linenumber up when we hit the LF (or a stand-alone CR).
        // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
        // and we advance immediately past the LF as well, returning both together as if
        // it was all a single 'character' only.
        var slice_len = 1;
        var lines = false;
        if (ch === '\n') {
            lines = true;
        } else if (ch === '\r') {
            lines = true;
            var ch2 = this._input[1];
            if (ch2 === '\n') {
                slice_len++;
                ch += ch2;
                this.yytext += ch2;
                this.yyleng++;
                this.offset++;
                this.match += ch2;
                this.matched += ch2;
                if (this.options.ranges) {
                    this.yylloc.range[1]++;
                }
            }
        }
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
        } else {
            this.yylloc.last_column++;
        }
        if (this.options.ranges) {
            this.yylloc.range[1]++;
        }

        this._input = this._input.slice(slice_len);
        return ch;
    },

    /**
    unshifts one char (or an entire string) into the input

    @public
    @this {RegExpLexer}
    */
    unput: function lexer_unput(ch) {
        var len = ch.length;
        var lines = ch.split(/(?:\r\n?|\n)/g);

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        this.yyleng = this.yytext.length;
        this.offset -= len;
        this.match = this.match.substr(0, this.match.length - len);
        this.matched = this.matched.substr(0, this.matched.length - len);

        if (lines.length > 1) {
            this.yylineno -= lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;
            var pre = this.match;
            var pre_lines = pre.split(/(?:\r\n?|\n)/g);
            if (pre_lines.length === 1) {
                pre = this.matched;
                pre_lines = pre.split(/(?:\r\n?|\n)/g);
            }
            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
        } else {
            this.yylloc.last_column -= len;
        }

        if (this.options.ranges) {
            this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
        }
        this.done = false;
        return this;
    },

    /**
    cache matched text and append it on next action

    @public
    @this {RegExpLexer}
    */
    more: function lexer_more() {
        this._more = true;
        return this;
    },

    /**
    signal the lexer that this rule fails to match the input, so the next matching rule (regex) should be tested instead.

    @public
    @this {RegExpLexer}
    */
    reject: function lexer_reject() {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            // when the `parseError()` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // `.lex()` run.
            var lineno_msg = '';
            if (this.options.trackPosition) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
            }
            var pos_str = this.showPosition();
            if (pos_str && pos_str[0] !== '\n') {
                pos_str = '\n' + pos_str;
            }
            var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).' + pos_str, false);
            this._signaled_error_token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
        }
        return this;
    },

    /**
    retain first n characters of the match

    @public
    @this {RegExpLexer}
    */
    less: function lexer_less(n) {
        return this.unput(this.match.slice(n));
    },

    /**
    return (part of the) already matched input, i.e. for error messages.

    Limit the returned string length to `maxSize` (default: 20).

    Limit the returned string to the `maxLines` number of lines of input (default: 1).

    Negative limit values equal *unlimited*.

    @public
    @this {RegExpLexer}
    */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
        var past = this.matched.substring(0, this.matched.length - this.match.length);
        if (maxSize < 0)
            maxSize = past.length;
        else if (!maxSize)
            maxSize = 20;
        if (maxLines < 0)
            maxLines = past.length;         // can't ever have more input lines than this!
        else if (!maxLines)
            maxLines = 1;
        // `substr` anticipation: treat \r\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        past = past.substr(-maxSize * 2 - 2);
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        var a = past.replace(/\r\n|\r/g, '\n').split('\n');
        a = a.slice(-maxLines);
        past = a.join('\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis prefix...
        if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
        }
        return past;
    },

    /**
    return (part of the) upcoming input, i.e. for error messages.

    Limit the returned string length to `maxSize` (default: 20).

    Limit the returned string to the `maxLines` number of lines of input (default: 1).

    Negative limit values equal *unlimited*.

    @public
    @this {RegExpLexer}
    */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
        var next = this.match;
        if (maxSize < 0)
            maxSize = next.length + this._input.length;
        else if (!maxSize)
            maxSize = 20;
        if (maxLines < 0)
            maxLines = maxSize;         // can't ever have more input lines than this!
        else if (!maxLines)
            maxLines = 1;
        // `substring` anticipation: treat \r\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        if (next.length < maxSize * 2 + 2) {
            next += this._input.substring(0, maxSize * 2 + 2);  // substring is faster on Chrome/V8
        }
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        var a = next.replace(/\r\n|\r/g, '\n').split('\n');
        a = a.slice(0, maxLines);
        next = a.join('\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis postfix...
        if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
        }
        return next;
    },

    /**
    return a string which displays the character position where the lexing error occurred, i.e. for error messages

    @public
    @this {RegExpLexer}
    */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
        var pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
        var c = new Array(pre.length + 1).join('-');
        return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
    },

    /**
    helper function, used to produce a human readable description as a string, given
    the input `yylloc` location object.

    Set `display_range_too` to TRUE to include the string character index position(s)
    in the description if the `yylloc.range` is available.

    @public
    @this {RegExpLexer}
    */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
        var l1 = yylloc.first_line;
        var l2 = yylloc.last_line;
        var o1 = yylloc.first_column;
        var o2 = yylloc.last_column;
        var dl = l2 - l1;
        var d_o = o2 - o1;
        var rv;
        if (dl === 0) {
            rv = 'line ' + l1 + ', ';
            if (d_o === 1) {
                rv += 'column ' + o1;
            } else {
                rv += 'columns ' + o1 + ' .. ' + o2;
            }
        } else {
            rv = 'lines ' + l1 + '(column ' + o1 + ') .. ' + l2 + '(column ' + o2 + ')';
        }
        if (yylloc.range && display_range_too) {
            var r1 = yylloc.range[0];
            var r2 = yylloc.range[1] - 1;
            if (r2 === r1) {
                rv += ' {String Offset: ' + r1 + '}';
            } else {
                rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
        }
        return rv;
        // return JSON.stringify(yylloc);
    },

    /**
    test the lexed token: return FALSE when not a match, otherwise return token.

    `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
    contains the actually matched text string.

    Also move the input cursor forward and update the match collectors:

    - `yytext`
    - `yyleng`
    - `match`
    - `matches`
    - `yylloc`
    - `offset`

    @public
    @this {RegExpLexer}
    */
    test_match: function lexer_test_match(match, indexed_rule) {
        var token,
            lines,
            backup,
            match_str,
            match_str_len;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.yylloc.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column,

                    range: (this.options.ranges ? this.yylloc.range.slice(0) :  undefined)
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                //_signaled_error_token: this._signaled_error_token,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(0),
                done: this.done
            };
        }

        match_str = match[0];
        match_str_len = match_str.length;
        // if (match_str.indexOf('\n') !== -1 || match_str.indexOf('\r') !== -1) {
            lines = match_str.split(/(?:\r\n?|\n)/g);
            if (lines.length > 1) {
                this.yylineno += lines.length - 1;

                this.yylloc.last_line = this.yylineno + 1,
                this.yylloc.last_column = lines[lines.length - 1].length;
            } else {
                this.yylloc.last_column += match_str_len;
            }
        // }
        this.yytext += match_str;
        this.match += match_str;
        this.matches = match;
        this.yyleng = this.yytext.length;
        if (this.options.ranges) {
            this.yylloc.range[1] += match_str_len;
        }
        // previous lex rules MAY have invoked the `more()` API rather than producing a token:
        // those rules will already have moved this `offset` forward matching their match lengths,
        // hence we must only add our own match length now:
        this.offset += match_str_len;
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match_str_len);
        this.matched += match_str;

        // calling this method:
        //
        //   function lexer__performAction(yy, yy_, $avoiding_name_collisions, YY_START) {...}
        token = this.performAction.call(this, this.yy, this, indexed_rule, this.conditionStack[this.conditionStack.length - 1] /* = YY_START */);
        // otherwise, when the action codes are all simple return token statements:
        //token = this.simpleCaseActionClusters[indexed_rule];

        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (var k in backup) {
                this[k] = backup[k];
            }
            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
        } else if (this._signaled_error_token) {
            // produce one 'error' token as `.parseError()` in `reject()` did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;
            this._signaled_error_token = false;
            return token;
        }
        return false;
    },

    /**
    return next match in input

    @public
    @this {RegExpLexer}
    */
    next: function lexer_next() {
        if (this.done) {
            this.clear();
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        var token,
            match,
            tempMatch,
            index;
        if (!this._more) {
            this.clear();
        }
        var spec = this.__currentRuleSet__;
        if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();
            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
                var lineno_msg = '';
                if (this.options.trackPosition) {
                    lineno_msg = ' on line ' + (this.yylineno + 1);
                }
                var pos_str = this.showPosition();
                if (pos_str && pos_str[0] !== '\n') {
                    pos_str = '\n' + pos_str;
                }
                var p = this.constructLexErrorInfo('Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!' + pos_str, false);
                // produce one 'error' token until this situation has been resolved, most probably by parse termination!
                return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            }
        }

        var rule_ids = spec.rules;
        //var dispatch = spec.__dispatch_lut;
        var regexes = spec.__rule_regexes;
        var len = spec.__rule_count;

        // Note: the arrays are 1-based, while `len` itself is a valid index,
        // hence the non-standard less-or-equal check in the next loop condition!
        for (var i = 1; i <= len; i++) {
            tempMatch = this._input.match(regexes[i]);
            if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;
                if (this.options.backtrack_lexer) {
                    token = this.test_match(tempMatch, rule_ids[i]);
                    if (token !== false) {
                        return token;
                    } else if (this._backtrack) {
                        match = undefined;
                        continue; // rule action called reject() implying a rule MISmatch.
                    } else {
                        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                        return false;
                    }
                } else if (!this.options.flex) {
                    break;
                }
            }
        }
        if (match) {
            token = this.test_match(match, rule_ids[index]);
            if (token !== false) {
                return token;
            }
            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
            return false;
        }
        if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
        } else {
            var lineno_msg = '';
            if (this.options.trackPosition) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
            }
            var pos_str = this.showPosition();
            if (pos_str && pos_str[0] !== '\n') {
                pos_str = '\n' + pos_str;
            }
            var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': Unrecognized text.' + pos_str, this.options.lexerErrorsAreRecoverable);
            token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            if (token === this.ERROR) {
                // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
                // by moving forward at least one character at a time:
                if (!this.match.length) {
                    this.input();
                }
            }
            return token;
        }
    },

    /**
    return next match that has a token

    @public
    @this {RegExpLexer}
    */
    lex: function lexer_lex() {
        var r;
        // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
        if (typeof this.options.pre_lex === 'function') {
            r = this.options.pre_lex.call(this);
        }
        while (!r) {
            r = this.next();
        }
        if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
        }
        return r;
    },

    /**
    backwards compatible alias for `pushState()`;
    the latter is symmetrical with `popState()` and we advise to use
    those APIs in any modern lexer code, rather than `begin()`.

    @public
    @this {RegExpLexer}
    */
    begin: function lexer_begin(condition) {
        return this.pushState(condition);
    },

    /**
    activates a new lexer condition state (pushes the new lexer condition state onto the condition stack)

    @public
    @this {RegExpLexer}
    */
    pushState: function lexer_pushState(condition) {
        this.conditionStack.push(condition);
        this.__currentRuleSet__ = null;
        return this;
    },

    /**
    pop the previously active lexer condition state off the condition stack

    @public
    @this {RegExpLexer}
    */
    popState: function lexer_popState() {
        var n = this.conditionStack.length - 1;
        if (n > 0) {
            this.__currentRuleSet__ = null;
            return this.conditionStack.pop();
        } else {
            return this.conditionStack[0];
        }
    },

    /**
    return the currently active lexer condition state; when an index argument is provided it produces the N-th previous condition state, if available

    @public
    @this {RegExpLexer}
    */
    topState: function lexer_topState(n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        } else {
            return 'INITIAL';
        }
    },

    /**
    (internal) determine the lexer rule set which is active for the currently active lexer condition state

    @public
    @this {RegExpLexer}
    */
    _currentRules: function lexer__currentRules() {
        if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
            return this.conditions[this.conditionStack[this.conditionStack.length - 1]];
        } else {
            return this.conditions['INITIAL'];
        }
    },

    /**
    return the number of states currently on the stack

    @public
    @this {RegExpLexer}
    */
    stateStackSize: function lexer_stateStackSize() {
        return this.conditionStack.length;
    },
    options: {
  xregexp: true,
  ranges: true,
  trackPosition: true,
  easy_keyword_rules: true
},
    JisonLexerError: JisonLexerError,
    performAction: function lexer__performAction(yy, yy_, $avoiding_name_collisions, YY_START) {

var YYSTATE = YY_START;
switch($avoiding_name_collisions) {
case 0 : 
/*! Conditions:: token */ 
/*! Rule::       {BR} */ 
 this.popState(); 
break;
case 1 : 
/*! Conditions:: token */ 
/*! Rule::       %% */ 
 this.popState(); 
break;
case 2 : 
/*! Conditions:: token */ 
/*! Rule::       ; */ 
 this.popState(); 
break;
case 3 : 
/*! Conditions:: bnf ebnf */ 
/*! Rule::       %% */ 
 this.pushState('code'); return 14; 
break;
case 17 : 
/*! Conditions:: options */ 
/*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */ 
 yy_.yytext = this.matches[1]; return 28;   // value is always a string type 
break;
case 18 : 
/*! Conditions:: options */ 
/*! Rule::       '{QUOTED_STRING_CONTENT}' */ 
 yy_.yytext = this.matches[1]; return 28;   // value is always a string type 
break;
case 19 : 
/*! Conditions:: INITIAL ebnf bnf token path options */ 
/*! Rule::       \/\/[^\r\n]* */ 
 /* skip single-line comment */ 
break;
case 20 : 
/*! Conditions:: INITIAL ebnf bnf token path options */ 
/*! Rule::       \/\*(.|\n|\r)*?\*\/ */ 
 /* skip multi-line comment */ 
break;
case 22 : 
/*! Conditions:: options */ 
/*! Rule::       {BR}{WS}+(?=\S) */ 
 /* skip leading whitespace on the next line of input, when followed by more options */ 
break;
case 23 : 
/*! Conditions:: options */ 
/*! Rule::       {BR} */ 
 this.popState(); return 26; 
break;
case 24 : 
/*! Conditions:: options */ 
/*! Rule::       {WS}+ */ 
 /* skip whitespace */ 
break;
case 25 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       {WS}+ */ 
 /* skip whitespace */ 
break;
case 26 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       {BR}+ */ 
 /* skip newlines */ 
break;
case 27 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       \[{ID}\] */ 
 yy_.yytext = this.matches[1]; return 38; 
break;
case 31 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */ 
 yy_.yytext = this.matches[1]; return 24; 
break;
case 32 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       '{QUOTED_STRING_CONTENT}' */ 
 yy_.yytext = this.matches[1]; return 24; 
break;
case 37 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %% */ 
 this.pushState(ebnf ? 'ebnf' : 'bnf'); return 14; 
break;
case 38 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %ebnf\b */ 
 if (!yy.options) { yy.options = {}; } ebnf = yy.options.ebnf = true; 
break;
case 39 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %debug\b */ 
 if (!yy.options) { yy.options = {}; } yy.options.debug = true; return 19; 
break;
case 46 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %token\b */ 
 this.pushState('token'); return 18; 
break;
case 48 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %options\b */ 
 this.pushState('options'); return 25; 
break;
case 49 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %lex{LEX_CONTENT}\/lex\b */ 
 
                                            // remove the %lex../lex wrapper and return the pure lex section:
                                            yy_.yytext = this.matches[1];
                                            return 17;
                                         
break;
case 52 : 
/*! Conditions:: INITIAL ebnf bnf code */ 
/*! Rule::       %include\b */ 
 this.pushState('path'); return 42; 
break;
case 53 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %{NAME}([^\r\n]*) */ 
 
                                            /* ignore unrecognized decl */
                                            console.warn('EBNF: ignoring unsupported parser option: ', yy_.yytext, ' while lexing in ', this.topState(), ' state');
                                            // this.pushState('options');
                                            yy_.yytext = [
                                                this.matches[1],            // {NAME}
                                                this.matches[2].trim()      // optional value/parameters
                                            ];
                                            return 20;
                                         
break;
case 54 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       <{ID}> */ 
 yy_.yytext = this.matches[1]; return 35; 
break;
case 55 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       \{\{[\w\W]*?\}\} */ 
 yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 4); return 15; 
break;
case 56 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       %\{(?:.|\r|\n)*?%\} */ 
 yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 4); return 15; 
break;
case 57 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       \{ */ 
 yy.depth = 0; this.pushState('action'); return 12; 
break;
case 58 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       ->.* */ 
 yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 2).trim(); return 40; 
break;
case 59 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       →.* */ 
 yy_.yytext = yy_.yytext.substr(1, yy_.yyleng - 1).trim(); return 40; 
break;
case 60 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       {HEX_NUMBER} */ 
 yy_.yytext = parseInt(yy_.yytext, 16); return 36; 
break;
case 61 : 
/*! Conditions:: bnf ebnf token INITIAL */ 
/*! Rule::       {DECIMAL_NUMBER}(?![xX0-9a-fA-F]) */ 
 yy_.yytext = parseInt(yy_.yytext, 10); return 36; 
break;
case 64 : 
/*! Conditions:: action */ 
/*! Rule::       \/[^ /]*?['"{}'][^ ]*?\/ */ 
 return 41; // regexp with braces or quotes (and no spaces) 
break;
case 69 : 
/*! Conditions:: action */ 
/*! Rule::       \{ */ 
 yy.depth++; return 12; 
break;
case 70 : 
/*! Conditions:: action */ 
/*! Rule::       \} */ 
 if (yy.depth === 0) { this.popState(); } else { yy.depth--; } return 13; 
break;
case 72 : 
/*! Conditions:: code */ 
/*! Rule::       [^\r\n]+ */ 
 return 44;      // the bit of CODE just before EOF... 
break;
case 73 : 
/*! Conditions:: path */ 
/*! Rule::       {BR} */ 
 this.popState(); this.unput(yy_.yytext); 
break;
case 74 : 
/*! Conditions:: path */ 
/*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */ 
 yy_.yytext = this.matches[1]; this.popState(); return 43; 
break;
case 75 : 
/*! Conditions:: path */ 
/*! Rule::       '{QUOTED_STRING_CONTENT}' */ 
 yy_.yytext = this.matches[1]; this.popState(); return 43; 
break;
case 76 : 
/*! Conditions:: path */ 
/*! Rule::       {WS}+ */ 
 // skip whitespace in the line 
break;
case 77 : 
/*! Conditions:: path */ 
/*! Rule::       [^\s\r\n]+ */ 
 this.popState(); return 43; 
break;
case 78 : 
/*! Conditions:: * */ 
/*! Rule::       . */ 
 
                                            /* b0rk on bad characters */
                                            var l0 = Math.max(0, yy_.yylloc.last_column - yy_.yylloc.first_column);
                                            var l2 = 39;
                                            var l1 = Math.min(79 - 4 - l0 - l2, yy_.yylloc.first_column, 0);
                                            var pos_str = this.showPosition(l1, l2);
                                            if (pos_str && pos_str[0] !== '\n') {
                                                pos_str = '\n\n       Offending input:\n' + indent(pos_str, 4);
                                            }
                                            yy_.yyerror('unsupported parser input: ' + dquote(yy_.yytext) + ' @ ' + this.describeYYLLOC(yy_.yylloc) + ' while lexing in ' + dquote(this.topState()) + ' state.' + pos_str);
                                         
break;
default:
  return this.simpleCaseActionClusters[$avoiding_name_collisions];
}
},
    simpleCaseActionClusters: {

  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       %empty\b */ 
   4 : 37,
  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       %epsilon\b */ 
   5 : 37,
  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       \u0190 */ 
   6 : 37,
  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       \u025B */ 
   7 : 37,
  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       \u03B5 */ 
   8 : 37,
  /*! Conditions:: bnf ebnf */ 
  /*! Rule::       \u03F5 */ 
   9 : 37,
  /*! Conditions:: ebnf */ 
  /*! Rule::       \( */ 
   10 : 7,
  /*! Conditions:: ebnf */ 
  /*! Rule::       \) */ 
   11 : 8,
  /*! Conditions:: ebnf */ 
  /*! Rule::       \* */ 
   12 : 9,
  /*! Conditions:: ebnf */ 
  /*! Rule::       \? */ 
   13 : 10,
  /*! Conditions:: ebnf */ 
  /*! Rule::       \+ */ 
   14 : 11,
  /*! Conditions:: options */ 
  /*! Rule::       {NAME} */ 
   15 : 27,
  /*! Conditions:: options */ 
  /*! Rule::       = */ 
   16 : 3,
  /*! Conditions:: options */ 
  /*! Rule::       [^\s\r\n]+ */ 
   21 : 29,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       {ID} */ 
   28 : 23,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       \$end\b */ 
   29 : 23,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       \$eof\b */ 
   30 : 23,
  /*! Conditions:: token */ 
  /*! Rule::       [^\s\r\n]+ */ 
   33 : 'TOKEN_WORD',
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       : */ 
   34 : 4,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       ; */ 
   35 : 5,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       \| */ 
   36 : 6,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %parser-type\b */ 
   40 : 31,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %prec\b */ 
   41 : 39,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %start\b */ 
   42 : 16,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %left\b */ 
   43 : 32,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %right\b */ 
   44 : 33,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %nonassoc\b */ 
   45 : 34,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %parse-param\b */ 
   47 : 30,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %code\b */ 
   50 : 22,
  /*! Conditions:: bnf ebnf token INITIAL */ 
  /*! Rule::       %import\b */ 
   51 : 21,
  /*! Conditions:: action */ 
  /*! Rule::       \/\*(.|\n|\r)*?\*\/ */ 
   62 : 41,
  /*! Conditions:: action */ 
  /*! Rule::       \/\/[^\r\n]* */ 
   63 : 41,
  /*! Conditions:: action */ 
  /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */ 
   65 : 41,
  /*! Conditions:: action */ 
  /*! Rule::       '{QUOTED_STRING_CONTENT}' */ 
   66 : 41,
  /*! Conditions:: action */ 
  /*! Rule::       [/"'][^{}/"']+ */ 
   67 : 41,
  /*! Conditions:: action */ 
  /*! Rule::       [^{}/"']+ */ 
   68 : 41,
  /*! Conditions:: code */ 
  /*! Rule::       [^\r\n]*(\r|\n)+ */ 
   71 : 44,
  /*! Conditions:: * */ 
  /*! Rule::       $ */ 
   79 : 1
},
    rules: [
        /^(?:(\r\n|\n|\r))/,
/^(?:%%)/,
/^(?:;)/,
/^(?:%%)/,
/^(?:%empty\b)/,
/^(?:%epsilon\b)/,
/^(?:\u0190)/,
/^(?:\u025B)/,
/^(?:\u03B5)/,
/^(?:\u03F5)/,
/^(?:\()/,
/^(?:\))/,
/^(?:\*)/,
/^(?:\?)/,
/^(?:\+)/,
new XRegExp("^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))", ""),
/^(?:=)/,
/^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
/^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
/^(?:\/\/[^\r\n]*)/,
/^(?:\/\*(.|\n|\r)*?\*\/)/,
/^(?:\S+)/,
/^(?:(\r\n|\n|\r)([^\S\n\r])+(?=\S))/,
/^(?:(\r\n|\n|\r))/,
/^(?:([^\S\n\r])+)/,
/^(?:([^\S\n\r])+)/,
/^(?:(\r\n|\n|\r)+)/,
new XRegExp("^(?:\\[([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\])", ""),
new XRegExp("^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))", ""),
/^(?:\$end\b)/,
/^(?:\$eof\b)/,
/^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
/^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
/^(?:\S+)/,
/^(?::)/,
/^(?:;)/,
/^(?:\|)/,
/^(?:%%)/,
/^(?:%ebnf\b)/,
/^(?:%debug\b)/,
/^(?:%parser-type\b)/,
/^(?:%prec\b)/,
/^(?:%start\b)/,
/^(?:%left\b)/,
/^(?:%right\b)/,
/^(?:%nonassoc\b)/,
/^(?:%token\b)/,
/^(?:%parse-param\b)/,
/^(?:%options\b)/,
/^(?:%lex((?:[^\S\n\r])*(?:(?:\r\n|\n|\r)[\S\s]*?)?(?:\r\n|\n|\r)(?:[^\S\n\r])*)\/lex\b)/,
/^(?:%code\b)/,
/^(?:%import\b)/,
/^(?:%include\b)/,
new XRegExp("^(?:%([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?)([^\\n\\r]*))", ""),
new XRegExp("^(?:<([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)>)", ""),
/^(?:\{\{[\w\W]*?\}\})/,
/^(?:%\{(?:.|\r|\n)*?%\})/,
/^(?:\{)/,
/^(?:->.*)/,
/^(?:→.*)/,
/^(?:(0[Xx][\dA-Fa-f]+))/,
/^(?:([1-9]\d*)(?![\dA-FXa-fx]))/,
/^(?:\/\*(.|\n|\r)*?\*\/)/,
/^(?:\/\/[^\r\n]*)/,
/^(?:\/[^ \/]*?["'{}][^ ]*?\/)/,
/^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
/^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
/^(?:[\/"'][^{}\/"']+)/,
/^(?:[^{}\/"']+)/,
/^(?:\{)/,
/^(?:\})/,
/^(?:[^\r\n]*(\r|\n)+)/,
/^(?:[^\r\n]+)/,
/^(?:(\r\n|\n|\r))/,
/^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
/^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
/^(?:([^\S\n\r])+)/,
/^(?:\S+)/,
/^(?:.)/,
/^(?:$)/
    ],
    conditions: {
  "bnf": {
    rules: [
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      19,
      20,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      78,
      79
    ],
    inclusive: true
  },
  "ebnf": {
    rules: [
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      19,
      20,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      78,
      79
    ],
    inclusive: true
  },
  "token": {
    rules: [
      0,
      1,
      2,
      19,
      20,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      78,
      79
    ],
    inclusive: true
  },
  "action": {
    rules: [
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      78,
      79
    ],
    inclusive: false
  },
  "code": {
    rules: [
      52,
      71,
      72,
      78,
      79
    ],
    inclusive: false
  },
  "path": {
    rules: [
      19,
      20,
      73,
      74,
      75,
      76,
      77,
      78,
      79
    ],
    inclusive: false
  },
  "options": {
    rules: [
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      78,
      79
    ],
    inclusive: false
  },
  "INITIAL": {
    rules: [
      19,
      20,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      78,
      79
    ],
    inclusive: true
  }
}
};


function indent(s, i) {
    var a = s.split('\n');
    var pf = (new Array(i + 1)).join(' ');
    return pf + a.join('\n' + pf);
}

// properly quote and escape the given input string
function dquote(s) {
    var sq = (s.indexOf('\'') >= 0);
    var dq = (s.indexOf('"') >= 0);
    if (sq && dq) {
        s = s.replace(/"/g, '\\"');
        dq = false;
    }
    if (dq) {
        s = '\'' + s + '\'';
    }
    else {
        s = '"' + s + '"';
    }
    return s;
};

return lexer;
})();
parser.lexer = lexer;

function Parser() {
  this.yy = {};
}
Parser.prototype = parser;
parser.Parser = Parser;

return new Parser();
})();




if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
  exports.parser = bnf;
  exports.Parser = bnf.Parser;
  exports.parse = function () {
    return bnf.parse.apply(bnf, arguments);
  };

}
